{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "#Load data\n",
    "url = 'https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv'\n",
    "dataset = pd.read_csv(url)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.columns[1:len(dataset.columns)-1]\n",
    "target = 'Churn'\n",
    "X = dataset[features]\n",
    "y = dataset[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.1'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5634, 6911)\n",
      "(1409, 6911)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "])\n",
    "X_train = preprocessing.fit_transform(X_train.values)\n",
    "X_test = preprocessing.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5634,)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_clf(hidden_layers=[64, 64, 64], dropout_rate=0, optimizer='adam', activation='relu', input_dim=12545, output_dim=1):\n",
    "    '''paraphrased from http://ethen8181.github.io/machine-learning/keras/nn_keras_hyperparameter_tuning.html'''    \n",
    "    model=Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation))\n",
    "    for index, layers in enumerate(hidden_layers[1:]):\n",
    "#         #Input layer + 1st Hidden Layer\n",
    "        if index:\n",
    "#             model.add(Dense(layers, input_dim=input_dim, activation=activation))\n",
    "        #hidden layers\n",
    "#         else:\n",
    "            model.add(Dense(layers, activation=activation))\n",
    "        #Dropout\n",
    "        if dropout_rate:\n",
    "            model.add(Dropout(rate=dropout_rate))\n",
    "    #Ouptut layer\n",
    "    if output_dim > 2:\n",
    "        model.add(Dense(output_dim), activation='softmax')\n",
    "        loss='categorical_crossentropy'\n",
    "    else:\n",
    "        model.add(Dense(output_dim, activation=activation))\n",
    "        loss='binary_crossentropy'\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=X_train.shape[1]\n",
    "output_dim=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed parameters\n",
    "model_keras = KerasClassifier(build_fn=keras_clf,\n",
    "                              input_dim=input_dim,\n",
    "                              output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_fit_params = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_epochs = range(10, 30, 4)\n",
    "range_layers = [[64, 64, 64, 64], [32, 32, 32, 32, 32], [100, 100, 100]]\n",
    "range_batchsize = range(20, 20000, 2000)\n",
    "range_optimizer = ['sgd', 'rmsprop', 'adagrad', 'adadelta', 'adam', 'adamax', 'nadam']\n",
    "range_activations = ['relu', 'tanh', 'sigmoid']\n",
    "range_dropouts = [n/100 for n in range(20, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_params_options = {\n",
    "    'epochs': range_epochs,\n",
    "    'dropout_rate': range_dropouts,\n",
    "    'batch_size': range_batchsize,\n",
    "    'optimizer': range_optimizer,\n",
    "    'activation': range_activations,\n",
    "#     'hidden_layers': range_layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3756/3756 [==============================] - 1s 203us/sample - loss: 2.5769 - acc: 0.6017\n",
      "Epoch 2/10\n",
      "3756/3756 [==============================] - 0s 101us/sample - loss: 2.3229 - acc: 0.6371\n",
      "Epoch 3/10\n",
      "3756/3756 [==============================] - 0s 103us/sample - loss: 2.2324 - acc: 0.6720\n",
      "Epoch 4/10\n",
      "3756/3756 [==============================] - 0s 100us/sample - loss: 2.0823 - acc: 0.6991\n",
      "Epoch 5/10\n",
      "3756/3756 [==============================] - 0s 102us/sample - loss: 1.9652 - acc: 0.7191\n",
      "Epoch 6/10\n",
      "3756/3756 [==============================] - 0s 102us/sample - loss: 1.9036 - acc: 0.7335\n",
      "Epoch 7/10\n",
      "3756/3756 [==============================] - 0s 101us/sample - loss: 1.8218 - acc: 0.7401\n",
      "Epoch 8/10\n",
      "3756/3756 [==============================] - 1s 162us/sample - loss: 1.6495 - acc: 0.7684\n",
      "Epoch 9/10\n",
      "3756/3756 [==============================] - 0s 119us/sample - loss: 1.5949 - acc: 0.7764\n",
      "Epoch 10/10\n",
      "3756/3756 [==============================] - 0s 100us/sample - loss: 1.6361 - acc: 0.7724\n",
      "1878/1878 [==============================] - 0s 210us/sample - loss: 2.3273 - acc: 0.6709\n",
      "Epoch 1/10\n",
      "3756/3756 [==============================] - 1s 214us/sample - loss: 2.6939 - acc: 0.5956\n",
      "Epoch 2/10\n",
      "3756/3756 [==============================] - 0s 120us/sample - loss: 2.5329 - acc: 0.6323\n",
      "Epoch 3/10\n",
      "3756/3756 [==============================] - 0s 117us/sample - loss: 2.3120 - acc: 0.6571\n",
      "Epoch 4/10\n",
      "3756/3756 [==============================] - 0s 126us/sample - loss: 2.0917 - acc: 0.6973\n",
      "Epoch 5/10\n",
      "3756/3756 [==============================] - 1s 153us/sample - loss: 2.0544 - acc: 0.6999\n",
      "Epoch 6/10\n",
      "3756/3756 [==============================] - 0s 113us/sample - loss: 1.9131 - acc: 0.7252\n",
      "Epoch 7/10\n",
      "3756/3756 [==============================] - 1s 188us/sample - loss: 1.7977 - acc: 0.7396\n",
      "Epoch 8/10\n",
      "3756/3756 [==============================] - 0s 123us/sample - loss: 1.7542 - acc: 0.7559\n",
      "Epoch 9/10\n",
      "3756/3756 [==============================] - 0s 129us/sample - loss: 1.5941 - acc: 0.7569\n",
      "Epoch 10/10\n",
      "3756/3756 [==============================] - 0s 126us/sample - loss: 1.6130 - acc: 0.7796\n",
      "1878/1878 [==============================] - 0s 173us/sample - loss: 2.2590 - acc: 0.6624\n",
      "Epoch 1/10\n",
      "3756/3756 [==============================] - 1s 179us/sample - loss: 2.7309 - acc: 0.6092\n",
      "Epoch 2/10\n",
      "3756/3756 [==============================] - 0s 126us/sample - loss: 2.4971 - acc: 0.6411\n",
      "Epoch 3/10\n",
      "3756/3756 [==============================] - 0s 119us/sample - loss: 2.2857 - acc: 0.6683\n",
      "Epoch 4/10\n",
      "3756/3756 [==============================] - 0s 101us/sample - loss: 2.1912 - acc: 0.6861\n",
      "Epoch 5/10\n",
      "3756/3756 [==============================] - 1s 154us/sample - loss: 2.0752 - acc: 0.7101\n",
      "Epoch 6/10\n",
      "3756/3756 [==============================] - 1s 151us/sample - loss: 1.8625 - acc: 0.7218\n",
      "Epoch 7/10\n",
      "3756/3756 [==============================] - 0s 130us/sample - loss: 1.8254 - acc: 0.7412\n",
      "Epoch 8/10\n",
      "3756/3756 [==============================] - 0s 106us/sample - loss: 1.8577 - acc: 0.7425\n",
      "Epoch 9/10\n",
      "3756/3756 [==============================] - 0s 121us/sample - loss: 1.5872 - acc: 0.7694\n",
      "Epoch 10/10\n",
      "3756/3756 [==============================] - 0s 106us/sample - loss: 1.5867 - acc: 0.7756\n",
      "1878/1878 [==============================] - 0s 166us/sample - loss: 2.1120 - acc: 0.6773\n",
      "WARNING:tensorflow:From C:\\Users\\tally\\.virtualenvs\\DS-Unit-4-Sprint-2-Neural-Networks-psAJyakQ\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:105: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/22\n",
      "3756/3756 [==============================] - 1s 189us/sample - loss: 0.6217 - acc: 0.6888\n",
      "Epoch 2/22\n",
      "3756/3756 [==============================] - 0s 102us/sample - loss: 0.6104 - acc: 0.7055\n",
      "Epoch 3/22\n",
      "3756/3756 [==============================] - 0s 113us/sample - loss: 0.5901 - acc: 0.7167\n",
      "Epoch 4/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.5903 - acc: 0.7210\n",
      "Epoch 5/22\n",
      "3756/3756 [==============================] - 1s 141us/sample - loss: 0.5885 - acc: 0.7228\n",
      "Epoch 6/22\n",
      "3756/3756 [==============================] - 1s 135us/sample - loss: 0.5882 - acc: 0.7292\n",
      "Epoch 7/22\n",
      "3756/3756 [==============================] - 0s 112us/sample - loss: 0.5845 - acc: 0.7255\n",
      "Epoch 8/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.5836 - acc: 0.7292\n",
      "Epoch 9/22\n",
      "3756/3756 [==============================] - 0s 112us/sample - loss: 0.5811 - acc: 0.7266\n",
      "Epoch 10/22\n",
      "3756/3756 [==============================] - 0s 112us/sample - loss: 0.5767 - acc: 0.7287\n",
      "Epoch 11/22\n",
      "3756/3756 [==============================] - 0s 113us/sample - loss: 0.5757 - acc: 0.7303\n",
      "Epoch 12/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.5732 - acc: 0.7282\n",
      "Epoch 13/22\n",
      "3756/3756 [==============================] - 0s 101us/sample - loss: 0.5610 - acc: 0.7351\n",
      "Epoch 14/22\n",
      "3756/3756 [==============================] - 0s 112us/sample - loss: 0.5577 - acc: 0.7346\n",
      "Epoch 15/22\n",
      "3756/3756 [==============================] - 0s 108us/sample - loss: 0.5574 - acc: 0.7354\n",
      "Epoch 16/22\n",
      "3756/3756 [==============================] - 0s 104us/sample - loss: 0.5486 - acc: 0.7420\n",
      "Epoch 17/22\n",
      "3756/3756 [==============================] - 0s 107us/sample - loss: 0.5542 - acc: 0.7396\n",
      "Epoch 18/22\n",
      "3756/3756 [==============================] - 0s 106us/sample - loss: 0.5499 - acc: 0.7364\n",
      "Epoch 19/22\n",
      "3756/3756 [==============================] - 0s 104us/sample - loss: 0.5453 - acc: 0.7378\n",
      "Epoch 20/22\n",
      "3756/3756 [==============================] - 0s 107us/sample - loss: 0.5421 - acc: 0.7425\n",
      "Epoch 21/22\n",
      "3756/3756 [==============================] - 1s 135us/sample - loss: 0.5388 - acc: 0.7417\n",
      "Epoch 22/22\n",
      "3756/3756 [==============================] - 0s 108us/sample - loss: 0.5351 - acc: 0.7481\n",
      "1878/1878 [==============================] - 1s 315us/sample - loss: 0.5675 - acc: 0.7311\n",
      "Epoch 1/22\n",
      "3756/3756 [==============================] - 1s 182us/sample - loss: 0.8262 - acc: 0.3978\n",
      "Epoch 2/22\n",
      "3756/3756 [==============================] - 0s 115us/sample - loss: 0.7774 - acc: 0.4460\n",
      "Epoch 3/22\n",
      "3756/3756 [==============================] - 0s 118us/sample - loss: 0.7650 - acc: 0.4574\n",
      "Epoch 4/22\n",
      "3756/3756 [==============================] - 0s 115us/sample - loss: 0.7318 - acc: 0.4965\n",
      "Epoch 5/22\n",
      "3756/3756 [==============================] - 0s 110us/sample - loss: 0.7138 - acc: 0.5245\n",
      "Epoch 6/22\n",
      "3756/3756 [==============================] - 0s 106us/sample - loss: 0.6978 - acc: 0.5466\n",
      "Epoch 7/22\n",
      "3756/3756 [==============================] - 0s 107us/sample - loss: 0.6811 - acc: 0.5684\n",
      "Epoch 8/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.6737 - acc: 0.5801\n",
      "Epoch 9/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.6617 - acc: 0.6116\n",
      "Epoch 10/22\n",
      "3756/3756 [==============================] - 0s 99us/sample - loss: 0.6565 - acc: 0.6060\n",
      "Epoch 11/22\n",
      "3756/3756 [==============================] - 0s 112us/sample - loss: 0.6510 - acc: 0.6147\n",
      "Epoch 12/22\n",
      "3756/3756 [==============================] - 0s 107us/sample - loss: 0.6413 - acc: 0.6254\n",
      "Epoch 13/22\n",
      "3756/3756 [==============================] - 0s 104us/sample - loss: 0.6323 - acc: 0.6435\n",
      "Epoch 14/22\n",
      "3756/3756 [==============================] - 0s 112us/sample - loss: 0.6351 - acc: 0.6371\n",
      "Epoch 15/22\n",
      "3756/3756 [==============================] - 0s 117us/sample - loss: 0.6295 - acc: 0.6528\n",
      "Epoch 16/22\n",
      "3756/3756 [==============================] - 0s 110us/sample - loss: 0.6148 - acc: 0.6656\n",
      "Epoch 17/22\n",
      "3756/3756 [==============================] - 0s 106us/sample - loss: 0.6107 - acc: 0.6723\n",
      "Epoch 18/22\n",
      "3756/3756 [==============================] - 0s 108us/sample - loss: 0.6077 - acc: 0.6672\n",
      "Epoch 19/22\n",
      "3756/3756 [==============================] - 0s 111us/sample - loss: 0.6026 - acc: 0.6821\n",
      "Epoch 20/22\n",
      "3756/3756 [==============================] - 0s 103us/sample - loss: 0.6027 - acc: 0.6885\n",
      "Epoch 21/22\n",
      "3756/3756 [==============================] - 0s 133us/sample - loss: 0.5981 - acc: 0.6997\n",
      "Epoch 22/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.5903 - acc: 0.6983\n",
      "1878/1878 [==============================] - 0s 193us/sample - loss: 0.6104 - acc: 0.7279\n",
      "Epoch 1/22\n",
      "3756/3756 [==============================] - 1s 210us/sample - loss: 0.8339 - acc: 0.3946\n",
      "Epoch 2/22\n",
      "3756/3756 [==============================] - 0s 114us/sample - loss: 0.7834 - acc: 0.4452\n",
      "Epoch 3/22\n",
      "3756/3756 [==============================] - 1s 152us/sample - loss: 0.7491 - acc: 0.4862\n",
      "Epoch 4/22\n",
      "3756/3756 [==============================] - 1s 154us/sample - loss: 0.7371 - acc: 0.4987\n",
      "Epoch 5/22\n",
      "3756/3756 [==============================] - 0s 117us/sample - loss: 0.7214 - acc: 0.5234\n",
      "Epoch 6/22\n",
      "3756/3756 [==============================] - 0s 120us/sample - loss: 0.7116 - acc: 0.5341\n",
      "Epoch 7/22\n",
      "3756/3756 [==============================] - 0s 118us/sample - loss: 0.6968 - acc: 0.5527\n",
      "Epoch 8/22\n",
      "3756/3756 [==============================] - 0s 125us/sample - loss: 0.6878 - acc: 0.5703\n",
      "Epoch 9/22\n",
      "3756/3756 [==============================] - 0s 132us/sample - loss: 0.6822 - acc: 0.5719\n",
      "Epoch 10/22\n",
      "3756/3756 [==============================] - 0s 127us/sample - loss: 0.6746 - acc: 0.5828\n",
      "Epoch 11/22\n",
      "3756/3756 [==============================] - 0s 127us/sample - loss: 0.6650 - acc: 0.6062\n",
      "Epoch 12/22\n",
      "3756/3756 [==============================] - 0s 111us/sample - loss: 0.6498 - acc: 0.6201\n",
      "Epoch 13/22\n",
      "3756/3756 [==============================] - 1s 133us/sample - loss: 0.6475 - acc: 0.6190\n",
      "Epoch 14/22\n",
      "3756/3756 [==============================] - 0s 114us/sample - loss: 0.6390 - acc: 0.6345\n",
      "Epoch 15/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.6334 - acc: 0.6371\n",
      "Epoch 16/22\n",
      "3756/3756 [==============================] - 0s 105us/sample - loss: 0.6361 - acc: 0.6398\n",
      "Epoch 17/22\n",
      "3756/3756 [==============================] - 0s 109us/sample - loss: 0.6338 - acc: 0.6494\n",
      "Epoch 18/22\n",
      "3756/3756 [==============================] - 0s 120us/sample - loss: 0.6187 - acc: 0.6651\n",
      "Epoch 19/22\n",
      "3756/3756 [==============================] - 0s 103us/sample - loss: 0.6152 - acc: 0.6696\n",
      "Epoch 20/22\n",
      "3756/3756 [==============================] - 0s 110us/sample - loss: 0.6170 - acc: 0.6667\n",
      "Epoch 21/22\n",
      "3756/3756 [==============================] - 0s 115us/sample - loss: 0.6109 - acc: 0.6699\n",
      "Epoch 22/22\n",
      "3756/3756 [==============================] - 0s 117us/sample - loss: 0.6016 - acc: 0.6824\n",
      "1878/1878 [==============================] - 0s 181us/sample - loss: 0.6049 - acc: 0.7444\n",
      "Epoch 1/18\n",
      "3756/3756 [==============================] - ETA: 0s - loss: 0.7136 - acc: 0.510 - 3s 671us/sample - loss: 0.7137 - acc: 0.5104\n",
      "Epoch 2/18\n",
      "3756/3756 [==============================] - 2s 534us/sample - loss: 0.7049 - acc: 0.5253\n",
      "Epoch 3/18\n",
      "3756/3756 [==============================] - 2s 536us/sample - loss: 0.6960 - acc: 0.5407\n",
      "Epoch 4/18\n",
      "3756/3756 [==============================] - 2s 533us/sample - loss: 0.6928 - acc: 0.5485\n",
      "Epoch 5/18\n",
      "3756/3756 [==============================] - 2s 491us/sample - loss: 0.6929 - acc: 0.5493\n",
      "Epoch 6/18\n",
      "3756/3756 [==============================] - 2s 478us/sample - loss: 0.6838 - acc: 0.5652\n",
      "Epoch 7/18\n",
      "3756/3756 [==============================] - 2s 492us/sample - loss: 0.6747 - acc: 0.5682\n",
      "Epoch 8/18\n",
      "3756/3756 [==============================] - 2s 484us/sample - loss: 0.6818 - acc: 0.5740\n",
      "Epoch 9/18\n",
      "3756/3756 [==============================] - 2s 496us/sample - loss: 0.6718 - acc: 0.5948\n",
      "Epoch 10/18\n",
      "3756/3756 [==============================] - 2s 517us/sample - loss: 0.6632 - acc: 0.6057\n",
      "Epoch 11/18\n",
      "3756/3756 [==============================] - 2s 511us/sample - loss: 0.6647 - acc: 0.5982\n",
      "Epoch 12/18\n",
      "3756/3756 [==============================] - 2s 616us/sample - loss: 0.6592 - acc: 0.6198s - lo\n",
      "Epoch 13/18\n",
      "3756/3756 [==============================] - 2s 548us/sample - loss: 0.6535 - acc: 0.6238\n",
      "Epoch 14/18\n",
      "3756/3756 [==============================] - 2s 506us/sample - loss: 0.6535 - acc: 0.6283\n",
      "Epoch 15/18\n",
      "3756/3756 [==============================] - 2s 493us/sample - loss: 0.6503 - acc: 0.6366\n",
      "Epoch 16/18\n",
      "3756/3756 [==============================] - 2s 489us/sample - loss: 0.6504 - acc: 0.6299\n",
      "Epoch 17/18\n",
      "3756/3756 [==============================] - 2s 488us/sample - loss: 0.6423 - acc: 0.6443\n",
      "Epoch 18/18\n",
      "3756/3756 [==============================] - 2s 510us/sample - loss: 0.6409 - acc: 0.6512\n",
      "1878/1878 [==============================] - 1s 433us/sample - loss: 0.6182 - acc: 0.7311\n",
      "Epoch 1/18\n",
      "3756/3756 [==============================] - 3s 688us/sample - loss: 0.6900 - acc: 0.5434\n",
      "Epoch 2/18\n",
      "3756/3756 [==============================] - 2s 527us/sample - loss: 0.6904 - acc: 0.5442\n",
      "Epoch 3/18\n",
      "3756/3756 [==============================] - 2s 572us/sample - loss: 0.6853 - acc: 0.5583\n",
      "Epoch 4/18\n",
      "3756/3756 [==============================] - 2s 559us/sample - loss: 0.6765 - acc: 0.5756\n",
      "Epoch 5/18\n",
      "3756/3756 [==============================] - 2s 555us/sample - loss: 0.6805 - acc: 0.5692\n",
      "Epoch 6/18\n",
      "3756/3756 [==============================] - 2s 554us/sample - loss: 0.6684 - acc: 0.5820\n",
      "Epoch 7/18\n",
      "3756/3756 [==============================] - 2s 550us/sample - loss: 0.6633 - acc: 0.6078\n",
      "Epoch 8/18\n",
      "3756/3756 [==============================] - 2s 547us/sample - loss: 0.6654 - acc: 0.6108\n",
      "Epoch 9/18\n",
      "3756/3756 [==============================] - 2s 544us/sample - loss: 0.6621 - acc: 0.6092\n",
      "Epoch 10/18\n",
      "3756/3756 [==============================] - 2s 593us/sample - loss: 0.6577 - acc: 0.6179\n",
      "Epoch 11/18\n",
      "3756/3756 [==============================] - 2s 573us/sample - loss: 0.6502 - acc: 0.6281\n",
      "Epoch 12/18\n",
      "3756/3756 [==============================] - 2s 539us/sample - loss: 0.6526 - acc: 0.6294\n",
      "Epoch 13/18\n",
      "3756/3756 [==============================] - 2s 526us/sample - loss: 0.6451 - acc: 0.6384\n",
      "Epoch 14/18\n",
      "3756/3756 [==============================] - 2s 543us/sample - loss: 0.6402 - acc: 0.6470s - loss: 0.6391 - ac\n",
      "Epoch 15/18\n",
      "3756/3756 [==============================] - 2s 522us/sample - loss: 0.6453 - acc: 0.6467\n",
      "Epoch 16/18\n",
      "3756/3756 [==============================] - 2s 498us/sample - loss: 0.6352 - acc: 0.6595\n",
      "Epoch 17/18\n",
      "3756/3756 [==============================] - 2s 511us/sample - loss: 0.6354 - acc: 0.6573\n",
      "Epoch 18/18\n",
      "3756/3756 [==============================] - 2s 491us/sample - loss: 0.6343 - acc: 0.6715\n",
      "1878/1878 [==============================] - 1s 372us/sample - loss: 0.6141 - acc: 0.7279\n",
      "Epoch 1/18\n",
      "3756/3756 [==============================] - 2s 618us/sample - loss: 0.9639 - acc: 0.2934\n",
      "Epoch 2/18\n",
      "3756/3756 [==============================] - 2s 501us/sample - loss: 0.9553 - acc: 0.2950\n",
      "Epoch 3/18\n",
      "3756/3756 [==============================] - 2s 507us/sample - loss: 0.9376 - acc: 0.3054\n",
      "Epoch 4/18\n",
      "3756/3756 [==============================] - 2s 508us/sample - loss: 0.9293 - acc: 0.3032\n",
      "Epoch 5/18\n",
      "3756/3756 [==============================] - 2s 510us/sample - loss: 0.9193 - acc: 0.3001\n",
      "Epoch 6/18\n",
      "3756/3756 [==============================] - 2s 559us/sample - loss: 0.9003 - acc: 0.3155\n",
      "Epoch 7/18\n",
      "3756/3756 [==============================] - 2s 535us/sample - loss: 0.8902 - acc: 0.3128\n",
      "Epoch 8/18\n",
      "3756/3756 [==============================] - 2s 520us/sample - loss: 0.8856 - acc: 0.3152s - loss: 0.\n",
      "Epoch 9/18\n",
      "3756/3756 [==============================] - 2s 541us/sample - loss: 0.8645 - acc: 0.3368\n",
      "Epoch 10/18\n",
      "3756/3756 [==============================] - 2s 564us/sample - loss: 0.8518 - acc: 0.3352\n",
      "Epoch 11/18\n",
      "3756/3756 [==============================] - 2s 560us/sample - loss: 0.8536 - acc: 0.3339\n",
      "Epoch 12/18\n",
      "3756/3756 [==============================] - 2s 551us/sample - loss: 0.8409 - acc: 0.3413s - loss:\n",
      "Epoch 13/18\n",
      "3756/3756 [==============================] - 2s 512us/sample - loss: 0.8196 - acc: 0.3757\n",
      "Epoch 14/18\n",
      "3756/3756 [==============================] - 2s 529us/sample - loss: 0.8119 - acc: 0.3783\n",
      "Epoch 15/18\n",
      "3756/3756 [==============================] - 2s 503us/sample - loss: 0.8029 - acc: 0.3735\n",
      "Epoch 16/18\n",
      "3756/3756 [==============================] - 2s 564us/sample - loss: 0.7942 - acc: 0.3839s - l\n",
      "Epoch 17/18\n",
      "3756/3756 [==============================] - 2s 544us/sample - loss: 0.7838 - acc: 0.4063\n",
      "Epoch 18/18\n",
      "3756/3756 [==============================] - 2s 561us/sample - loss: 0.7713 - acc: 0.4212\n",
      "1878/1878 [==============================] - 1s 483us/sample - loss: 0.7497 - acc: 0.2662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "5634/5634 [==============================] - 1s 189us/sample - loss: 0.8363 - acc: 0.3829\n",
      "Epoch 2/22\n",
      "5634/5634 [==============================] - 1s 123us/sample - loss: 0.7864 - acc: 0.4398\n",
      "Epoch 3/22\n",
      "5634/5634 [==============================] - 1s 112us/sample - loss: 0.7636 - acc: 0.4718\n",
      "Epoch 4/22\n",
      "5634/5634 [==============================] - 1s 116us/sample - loss: 0.7420 - acc: 0.4945\n",
      "Epoch 5/22\n",
      "5634/5634 [==============================] - 1s 113us/sample - loss: 0.7189 - acc: 0.5252\n",
      "Epoch 6/22\n",
      "5634/5634 [==============================] - 1s 114us/sample - loss: 0.7094 - acc: 0.5355\n",
      "Epoch 7/22\n",
      "5634/5634 [==============================] - 1s 106us/sample - loss: 0.6951 - acc: 0.5580\n",
      "Epoch 8/22\n",
      "5634/5634 [==============================] - 1s 108us/sample - loss: 0.6793 - acc: 0.5742\n",
      "Epoch 9/22\n",
      "5634/5634 [==============================] - 1s 103us/sample - loss: 0.6750 - acc: 0.5840\n",
      "Epoch 10/22\n",
      "5634/5634 [==============================] - 1s 106us/sample - loss: 0.6668 - acc: 0.5905\n",
      "Epoch 11/22\n",
      "5634/5634 [==============================] - 1s 100us/sample - loss: 0.6619 - acc: 0.5973\n",
      "Epoch 12/22\n",
      "5634/5634 [==============================] - 1s 107us/sample - loss: 0.6502 - acc: 0.6141\n",
      "Epoch 13/22\n",
      "5634/5634 [==============================] - 1s 102us/sample - loss: 0.6412 - acc: 0.6294\n",
      "Epoch 14/22\n",
      "5634/5634 [==============================] - 1s 111us/sample - loss: 0.6356 - acc: 0.6329\n",
      "Epoch 15/22\n",
      "5634/5634 [==============================] - 1s 108us/sample - loss: 0.6280 - acc: 0.6505\n",
      "Epoch 16/22\n",
      "5634/5634 [==============================] - 1s 103us/sample - loss: 0.6229 - acc: 0.6578\n",
      "Epoch 17/22\n",
      "5634/5634 [==============================] - 1s 106us/sample - loss: 0.6158 - acc: 0.6610\n",
      "Epoch 18/22\n",
      "5634/5634 [==============================] - 1s 101us/sample - loss: 0.6176 - acc: 0.6647\n",
      "Epoch 19/22\n",
      "5634/5634 [==============================] - 1s 105us/sample - loss: 0.6055 - acc: 0.6860\n",
      "Epoch 20/22\n",
      "5634/5634 [==============================] - 1s 102us/sample - loss: 0.6047 - acc: 0.6846\n",
      "Epoch 21/22\n",
      "5634/5634 [==============================] - 1s 103us/sample - loss: 0.5988 - acc: 0.6860\n",
      "Epoch 22/22\n",
      "5634/5634 [==============================] - 1s 105us/sample - loss: 0.5961 - acc: 0.6906\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model_keras,\n",
    "                            param_distributions=keras_params_options,\n",
    "                            cv=3,\n",
    "                            n_iter=3,\n",
    "                            n_jobs=1,\n",
    "                            verbose=1)\n",
    "best = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x1b4098edcc8>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.best_estimator_.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (NN)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
